{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# PUT THIS IMPORT BACK IN LATER!! There is something messed up my pip data for matplotlib for now\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# for displaying text with formatting later\n",
    "from IPython.display import display, HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the utility functions for the World Bank and OECD.\n",
    "# It requires changing the path to import properly in Python\n",
    "import sys\n",
    "sys.path.append('../utility_functions')\n",
    "\n",
    "from world_bank_oecd_utility_functions import (get_indicator_name_from_code, get_indicator_definition_or_additional_info_from_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change the variable OECD below to True if you want to use the OECD dataset or False if you want to use the World Bank dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data\n",
    "datasets = [\"../OECD/Cleaned/HEALTH_MERGED_Threshold_80_n3.csv\", \"../WorldBankDatasets/Cleaned/AllMerged_Threshold_85_n3_MMRTNE.csv\"]\n",
    "\n",
    "# OECD = False  # False for WB data\n",
    "OECD = True\n",
    "\n",
    "mapping_df = ''\n",
    "\n",
    "mapping_oecd_to_names_and_additional_info_df = pd.read_csv('../OECD/Cleaned/OECD_Indicator_Definition_Info.csv',\n",
    "                                                             # delimiter=',')\n",
    "                                                             delimiter=',')\n",
    "mapping_world_bank_to_names_and_definitions_df = pd.read_csv('../WorldBankDatasets/Cleaned/World_Bank_Indicator_Definition_Info.csv',\n",
    "                                                             delimiter='\\t')\n",
    "\n",
    "# remove an annoying column if it exists in the mapping for World Bank\n",
    "if \"Unnamed: 3\" in mapping_world_bank_to_names_and_definitions_df.columns:\n",
    "    mapping_world_bank_to_names_and_definitions_df = mapping_world_bank_to_names_and_definitions_df.drop(columns=[\"Unnamed: 3\"])\n",
    "\n",
    "if OECD:\n",
    "    mapping_df = mapping_oecd_to_names_and_additional_info_df\n",
    "    df = pd.read_csv(datasets[0])\n",
    "    mm_ind = \"MATIMATM\"\n",
    "else:\n",
    "    mapping_df = mapping_world_bank_to_names_and_definitions_df\n",
    "    df = pd.read_csv(datasets[1])\n",
    "    mm_ind = \"SH.STA.MMRT.NE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to see the oecd mapping csv that maps each indicator code to the name and additional information\n",
    "# mapping_oecd_to_names_and_additional_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to see the world bank mapping csv that maps each indicator code to the name and definition\n",
    "# mapping_world_bank_to_names_and_definitions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing cell to test the oecd and world bank mapping functions. Change OECD binary value to test the either oecd or world bank\n",
    "# sets\n",
    "\n",
    "# OECD = False\n",
    "# # OECD = True\n",
    "\n",
    "# if OECD:\n",
    "#     mapping_df = mapping_oecd_to_names_and_additional_info_df\n",
    "#     df = pd.read_csv(datasets[0])\n",
    "#     mm_ind = \"MATIMATM\"\n",
    "# else:\n",
    "#     mapping_df = mapping_world_bank_to_names_and_definitions_df\n",
    "#     df = pd.read_csv(datasets[1])\n",
    "#     mm_ind = \"SH.STA.MMRT.NE\"\n",
    "\n",
    "# # Test switching\n",
    "# if (OECD):\n",
    "#     code = 'ECONAICO'\n",
    "\n",
    "# else:\n",
    "#     code = 'SH.ANM.NPRG.ZS'\n",
    "# test1  = get_indicator_name_from_code(code, mapping_df)\n",
    "# print(test1)\n",
    "# test2 = get_indicator_definition_or_additional_info_from_code(code, mapping_df)\n",
    "# print(test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce to only gender indicators\n",
    "\n",
    "#if not OECD:\n",
    "#    gender_ind = pd.read_csv('../WorldBankDatasets/Gender_WorldBankData.csv').columns\n",
    "#    df = df.drop(columns=[col for col in df if col not in gender_ind])\n",
    "\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select year\n",
    "year = 2015\n",
    "df = df[df[\"Year\"] == year]\n",
    "df.drop(\"Year\", axis=1, inplace=True)\n",
    "\n",
    "# Scale predictor, which is currently unscaled\n",
    "scaler = MinMaxScaler()\n",
    "df[mm_ind] = scaler.fit_transform(df[mm_ind].to_numpy().reshape(-1, 1))\n",
    "\n",
    "# Drop country\n",
    "X = df.drop(columns=['Country'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2, random_state=42)\n",
    "pca.fit(X)\n",
    "\n",
    "print(\"Number of PCs: {}\".format(len(pca.explained_variance_ratio_)))\n",
    "print(\"Explained variation per PC: {}\".format(pca.explained_variance_ratio_))\n",
    "print(\"Sum of explained variation: {}\".format(pca.explained_variance_ratio_.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now to show you detailed information of the features that contribute to the PC analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note this only works one loading set at a time. For example if I had\n",
    "# pca_loadings = pca.components_\n",
    "# the code would only work for 1 set, for example pca_loadings[0]\n",
    "def sort_loading_set_for_principal_component(loadings, X=X):\n",
    "    feature_names = X.columns\n",
    "    \n",
    "    # make a series of the current pca loadings. Index is the column name (feature) and value is the loading value\n",
    "    feature_names_series = pd.Series(loadings, index=feature_names)\n",
    "\n",
    "    # take the absolute value of the series\n",
    "    feature_names_series_abs = feature_names_series.abs()\n",
    "\n",
    "    # finally sort descending. The higher the number, the higher the correlatino and explanatory value of the \n",
    "    # feature for the principal component\n",
    "    pca_component_explanatory_features_sorted = feature_names_series_abs.sort_values(ascending=False)\n",
    "    \n",
    "    return pca_component_explanatory_features_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment below to test the function sort_loading_set_for_principal_component\n",
    "\n",
    "# percentage_of_variance_to_explain = 0.8\n",
    "# pca = PCA(n_components=percentage_of_variance_to_explain, random_state=42)\n",
    "# pca.fit(X)\n",
    "# pca_loadings = pca.components_\n",
    "\n",
    "# sort_loading_set_for_principal_component(pca_loadings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now works for World Bank or OECD\n",
    "def get_most_important_features_from_pca_loading_set (pca_loading_set, mapping_df,\n",
    "                                                   n_most_important_features_from_loading = 5, \n",
    "                                                   includeName = True, includeDefinitionOrAdditionalInfo = True):\n",
    "    pca_loadings_explanations = {}\n",
    "\n",
    "    # get just the top n_most_important_features_from_loading features\n",
    "    cur_loadings_sorted_with_n_most_important_features = sort_loading_set_for_principal_component(pca_loading_set).iloc[\n",
    "        0:n_most_important_features_from_loading]\n",
    "\n",
    "    feature_codes = []\n",
    "    feature_values = []\n",
    "    feature_names = []\n",
    "    feature_definitions_or_additional_info = []\n",
    "\n",
    "    for feature_code_index, feature_value in zip (cur_loadings_sorted_with_n_most_important_features.index,\n",
    "                                                  cur_loadings_sorted_with_n_most_important_features.values):\n",
    "        feature_codes.append(feature_code_index)\n",
    "        feature_values.append(feature_value)\n",
    "\n",
    "        if (includeName):\n",
    "            cur_name = get_indicator_name_from_code(feature_code_index, mapping_df)\n",
    "            # print('cur_name is', cur_name)\n",
    "            feature_names.append(cur_name)\n",
    "        \n",
    "        if (includeDefinitionOrAdditionalInfo):\n",
    "            cur_definition_or_additional_info = get_indicator_definition_or_additional_info_from_code (feature_code_index,\n",
    "                                                                                                mapping_df)\n",
    "            feature_definitions_or_additional_info.append(cur_definition_or_additional_info)\n",
    "\n",
    "    pca_loadings_explanations[\"most_important_feature_values\"] = feature_values\n",
    "    pca_loadings_explanations[\"most_important_codes\"] = feature_codes\n",
    "    pca_loadings_explanations[\"most_important_feature_names\"] = feature_names\n",
    "    pca_loadings_explanations[\"most_important_definitions_or_additional_info\"] = feature_definitions_or_additional_info\n",
    "\n",
    "    return pca_loadings_explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment below to test the function get_most_important_features_from_pca_loading_set\n",
    "\n",
    "# percentage_of_variance_to_explain = 0.8\n",
    "# pca = PCA(n_components=percentage_of_variance_to_explain, random_state=42)\n",
    "# pca.fit(X)\n",
    "# pca_loadings = pca.components_\n",
    "\n",
    "# get_most_important_features_from_pca_loading_set(pca_loadings[0], mapping_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_most_important_features_from_pca_loading_set(pca_loadings[1], mapping_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will show the top most important components explaining the variance for each of the pcs \n",
    "# give a given percentage of variance to explain\n",
    "# now supports either world bank or OECD\n",
    "def pca_with_detailed_variance_and_components_info (percentage_of_variance_to_explain, mapping_df, X=X,\n",
    "                                                              n_most_important_features_from_loading=5,\n",
    "                                                              includeValues = False, includeDefinitionOrAdditionalInfo=False):\n",
    "    \n",
    "    pca = PCA(n_components=percentage_of_variance_to_explain, random_state=42)\n",
    "    pca.fit(X)\n",
    "    pca_loadings = pca.components_\n",
    "\n",
    "    loadings_information = []\n",
    "    for loading in pca_loadings:\n",
    "        cur_loading_features_info = get_most_important_features_from_pca_loading_set (loading, mapping_df,\n",
    "                                                                                  n_most_important_features_from_loading)\n",
    "        loadings_information.append(cur_loading_features_info)\n",
    "    \n",
    "    num_principal_components = len(pca.explained_variance_ratio_)\n",
    "\n",
    "    print(f'in order to explain {percentage_of_variance_to_explain * 100} percentage of the variance with pca it requires')\n",
    "    print(f'{num_principal_components} principal components')\n",
    "    print(f'the most important feature names, for the top {n_most_important_features_from_loading} from each PC, are\\n')\n",
    "\n",
    "    # print the most important value names\n",
    "    for i in range(0, len(loadings_information)):\n",
    "        # print('\\n')\n",
    "        print('---------')\n",
    "        print(f'For Principal Component {i+1}, the most important features names are:\\n')\n",
    "        # print('\\n')\n",
    "        cur_loadings_info = loadings_information[i]\n",
    "\n",
    "        cur_loadings_names = cur_loadings_info['most_important_feature_names']\n",
    "        cur_loadings_values = cur_loadings_info['most_important_feature_values']\n",
    "        cur_loadings_codes = cur_loadings_info['most_important_codes']\n",
    "        cur_loadings_definitions_or_additional_info = cur_loadings_info['most_important_definitions_or_additional_info']\n",
    "        # most_important_definitions_or_additional_info\n",
    "\n",
    "        for code, value, name, definition_or_additional_info in zip(cur_loadings_codes, cur_loadings_values, cur_loadings_names,\n",
    "                                                 cur_loadings_definitions_or_additional_info):\n",
    "            print(name)\n",
    "            \n",
    "            # uncomment for testing to debug\n",
    "            # print(code)\n",
    "\n",
    "            if (includeValues):\n",
    "                print(f\"with value {value}\")\n",
    "\n",
    "            if (includeDefinitionOrAdditionalInfo):\n",
    "                print(definition_or_additional_info)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify variance_percentage_to_explain below for detailed information based on what percentage of the variance in principal components you want to explain maternal mortality. (see section below for just the top feature per PC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_percentage_to_explain = 0.8\n",
    "# variance_percentage_to_explain = 0.9\n",
    "num_top_features_per_pc = 5\n",
    "pca_with_detailed_variance_and_components_info (variance_percentage_to_explain, mapping_df,\n",
    "                                                includeValues=True,\n",
    "                                                n_most_important_features_from_loading = num_top_features_per_pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a list of the top feature name for each principal component\n",
    "def get_top_feature_for_each_pc (percentage_of_variance_to_explain, X=X, n_most_important_features_from_loading=5):\n",
    "    pca = PCA(n_components=percentage_of_variance_to_explain, random_state=42)\n",
    "    pca.fit(X)\n",
    "    pca_loadings = pca.components_\n",
    "\n",
    "    loadings_information = []\n",
    "    for loading in pca_loadings:\n",
    "        cur_loading_features_info = get_most_important_features_from_pca_loading_set(loading, mapping_df,\n",
    "                                                                                  n_most_important_features_from_loading)\n",
    "        loadings_information.append(cur_loading_features_info)\n",
    "    \n",
    "    top_feature_name_per_pc = []\n",
    "    for i in range(0, len(loadings_information)):\n",
    "        cur_loadings_info = loadings_information[i]\n",
    "\n",
    "        cur_features_names = cur_loadings_info['most_important_feature_names']\n",
    "        cur_top_feature = cur_features_names[0]\n",
    "        top_feature_name_per_pc.append(cur_top_feature)\n",
    "        # cur_loadings_values = cur_loadings_info['most_important_features_values']\n",
    "        # cur_loadings_codes = cur_loadings_info['most_important_features_world_bank_codes']\n",
    "        # cur_loadings_definitions = cur_loadings_info['most_important_features_world_bank_definitions']\n",
    "    \n",
    "    return top_feature_name_per_pc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify variance_percentage_to_explain below based on what percentage of the variance in principal components. You may find the results interesting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below starts to use html formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variance_percentage_to_explain = 0.2\n",
    "# variance_percentage_to_explain = 0.3\n",
    "# variance_percentage_to_explain = 0.5\n",
    "# variance_percentage_to_explain = 0.8\n",
    "# variance_percentage_to_explain = 0.85\n",
    "# variance_percentage_to_explain = 0.9\n",
    "variance_percentage_to_explain = 0.95\n",
    "\n",
    "top_feature_names_for_pc_loadings = get_top_feature_for_each_pc(variance_percentage_to_explain)\n",
    "\n",
    "# print(f\"\"\"Assuming you want to explain {variance_percentage_to_explain * 100} percent of the PC variation, \n",
    "# for maternal morality, the top feature names that explain this per principal component are:\\n\"\"\")\n",
    "\n",
    "if OECD:\n",
    "    dataset_using = 'OECD'\n",
    "else:\n",
    "    dataset_using = 'World Bank Dataset'\n",
    "\n",
    "display( HTML(f\"\"\"<h2>Assuming you want to explain {variance_percentage_to_explain * 100} percent of the PC variation in the {dataset_using}, \n",
    "              the top feature names that explain this per principal component are:</h2>\\n\"\"\"))\n",
    "\n",
    "for i in range(0, len(top_feature_names_for_pc_loadings)):\n",
    "    #print(f\"for PC {i+1} the top explaining feature is: {top_feature_names_for_pc_loadings[i]}\")\n",
    "    # print(f\"PC {i+1}: {top_feature_names_for_pc_loadings[i]}\")\n",
    "    display( HTML( f\"<strong>PC {i+1}:</strong> {top_feature_names_for_pc_loadings[i]}\" ) )\n",
    "    # print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
