{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-hacker",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-asian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import shap \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# df_MMRT = pd.read_csv('WorldBankDatasets/Cleaned/AllMerged_Threshold_85_n3_MMRT.csv')\n",
    "df_MMRTNE = pd.read_csv('../WorldBankDatasets/Cleaned/AllMerged_Threshold_85_n3_MMRTNE.csv')\n",
    "df_OECD = pd.read_csv('../OECD/Cleaned/HEALTH_MERGED_Threshold_80_n3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-burlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "######  select which df to use \n",
    "\n",
    "df = df_MMRTNE\n",
    "indicator_y = 'SH.STA.MMRT.NE'\n",
    "\n",
    "#df = df_MMRT\n",
    "#indicator_y = 'SH.STA.MMRT'\n",
    "\n",
    "\n",
    "#df = df_OECD\n",
    "#indicator_y = 'MATIMATM'\n",
    "\n",
    "# Perform hyper parameter tuning? \n",
    "perform_hp_tuning = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-attendance",
   "metadata": {},
   "source": [
    "## Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-quantum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First need to encode the country \n",
    "\n",
    "# Create a LabelEncoder instance for each categorical column\n",
    "country_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the categorical columns\n",
    "data_encoded = df.copy(deep = True)\n",
    "data_encoded['Country'] = country_encoder.fit_transform(data_encoded['Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-alabama",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out Maternal Mortality as the predictor variable \n",
    "X = data_encoded.drop(columns= indicator_y)\n",
    "y = data_encoded[indicator_y]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-infection",
   "metadata": {},
   "source": [
    "### 5 fold cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-contest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_fold_cv(model):\n",
    "    \n",
    "    # Create a list to store the mean squared errors (MSE) for each fold\n",
    "    mse_scores = []\n",
    "    r2_scores = []\n",
    "    \n",
    "    # initialize the best r2 score as 0\n",
    "    best_r2_score = -100000\n",
    "    best_model = None\n",
    "    \n",
    "    # Create a KFold cross-validator with 5 folds\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Perform 5-fold cross-validation\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "        # Train the model on the training data\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions on the test data\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Calculate the mean squared error (MSE) for this fold\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mse_scores.append(mse)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        r2_scores.append(r2)\n",
    "        \n",
    "        # Keep the best model based on r2 score\n",
    "        if r2 > best_r2_score:\n",
    "            # Save the best r2 score and best model\n",
    "            best_r2_score = r2\n",
    "            best_model = model\n",
    "            # Save the respective train test split\n",
    "            X_train_best = X_train\n",
    "            X_test_best = X_test\n",
    "            y_train_best = y_train\n",
    "            y_test_best = y_test\n",
    "\n",
    "    # Calculate the mean and standard deviation of the MSE scores and r2 scores\n",
    "    mean_mse = np.mean(mse_scores)\n",
    "    std_mse = np.std(mse_scores)\n",
    "    mean_r2 = np.mean(r2_scores)\n",
    "    std_r2 = np.std(r2_scores)\n",
    "\n",
    "    print(f\"Average Mean Squared Error (MSE): {mean_mse}\")\n",
    "    print(f\"Standard Deviation of Mean Squared Error (MSE): {std_mse}\")\n",
    "    print(f\"Mean R-squared (R2): {mean_r2}\")\n",
    "    print(f\"Standard Deviation of R-squared (R2): {std_r2}\")\n",
    "    print(f\"Best R-squared (R2): {best_r2_score}\")\n",
    "    \n",
    "    return best_model, X_train_best, X_test_best, y_train_best, y_test_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-advisory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Run five-fold CV \n",
    "best_linear_regression, X_train, X_test, y_train, y_test = five_fold_cv(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-drinking",
   "metadata": {},
   "source": [
    "## Including Lasso Regression and Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-banana",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if perform_hp_tuning:\n",
    "    # Create a Lasso regression model\n",
    "    lasso_model = Lasso()\n",
    "\n",
    "    # Define a range of alpha values to tune\n",
    "    alpha_values = [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09,\n",
    "                    0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, \n",
    "                    1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]  \n",
    "\n",
    "    # Create a parameter grid for GridSearchCV\n",
    "    param_grid = {'alpha': alpha_values}\n",
    "\n",
    "    # Create a GridSearchCV object with cross-validation\n",
    "    grid_search = GridSearchCV(lasso_model, param_grid, cv=5)  \n",
    "\n",
    "    # Fit the grid search to the data\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    # Get the best alpha value\n",
    "    best_alpha = grid_search.best_params_['alpha']\n",
    "\n",
    "    # Get the best Lasso model\n",
    "    best_lasso_model = grid_search.best_estimator_\n",
    "    \n",
    "else: \n",
    "    if indicator_y == 'MATIMATM':\n",
    "        best_alpha = 0.06 # value found in hyperparameter tuning for OECD\n",
    "    elif indicator_y == 'SH.STA.MMRT.NE': \n",
    "        best_alpha = 0.02 # value found in hyperparameter tuning for World Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-desktop",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish Lasso model\n",
    "lasso_model = Lasso(alpha=best_alpha)\n",
    "# Run five-fold CV \n",
    "best_lasso_model, X_train, X_test, y_train, y_test  = five_fold_cv(lasso_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "democratic-wichita",
   "metadata": {},
   "source": [
    "### A look into model performance for Lasso model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-orchestra",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_linear_reg(X, y, yp, country, title):\n",
    "\n",
    " # X - X_test\n",
    " # y - y_test\n",
    " # yp - y_pred\n",
    " # country - list of country abbreviations ie. ['USA']\n",
    "\n",
    "    if country == None: \n",
    "\n",
    "        # Plot the data points and the regression line\n",
    "        plt.figure(figsize=(30, 20))\n",
    "        plt.scatter(X['Year'], y, color='blue', label='Data')\n",
    "        plt.scatter(X['Year'], yp, color='red',  label='Linear Regression')\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel('Maternal Mortality Ratio')\n",
    "        plt.title(title)\n",
    "        plt.legend()\n",
    "        plt.figure(figsize=(30, 20))\n",
    "        plt.show()\n",
    "        \n",
    "    else: \n",
    "        # Country encoding \n",
    "        encoded_values = country_encoder.transform(country)\n",
    "        # looking at just the secific country predictions in test partition\n",
    "\n",
    "        # Use boolean indexing to select the subset of the DataFrame\n",
    "        condition = X['Country'].isin(encoded_values)\n",
    "        X_test = X[condition]['Year']\n",
    "        y_test = y.loc[X_test.index]\n",
    "\n",
    "        # take the array index in order to pull the relevant y_pred  \n",
    "        index_positions = [y.index.get_loc(index) for index in X_test.index]\n",
    "        \n",
    "        y_pred = [yp[i] for i in index_positions]\n",
    "        \n",
    "        # Plot the data points and the regression line\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.scatter(X_test, y_test, color='blue', label='Data')\n",
    "        plt.scatter(X_test, y_pred, color='red',  label='Linear Regression')\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel('Maternal Mortality Ratio')\n",
    "        plt.title(title)\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-patch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data for Lasso Model\n",
    "y_pred_lasso = best_lasso_model.predict(X_test)\n",
    "\n",
    "plot_linear_reg(X_test, y_test, y_pred_lasso, country = None, title = 'Maternal Mortality All Developed Nations, Lasso Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-hardware",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_linear_reg(X_test, y_test, y_pred, country = ['USA'], title = 'Maternal Mortality Predictions USA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-annotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_linear_reg(X_test, y_test, y_pred, country = ['DEU'], title = 'Maternal Mortality Predictions Germany')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-session",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_linear_reg(X_test, y_test, y_pred, country = ['DEU', 'USA'], title = 'Maternal Mortality Predictions USA + Germany')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-arbor",
   "metadata": {},
   "source": [
    "## Shapley Values for Lasso Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-russian",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.LinearExplainer(best_lasso_model, X_train)\n",
    "\n",
    "# look at the features for all instances\n",
    "shap_values = explainer.shap_values(X_test) \n",
    "\n",
    "shap.summary_plot(shap_values)\n",
    "\n",
    "#shap_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-serial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the Shapley values and the feature names into a DataFrame\n",
    "shap_df = pd.DataFrame(data=shap_values, columns=X_test.columns)\n",
    "\n",
    "# Pull the top shapley features \n",
    "top_features = shap_df.iloc[0, :].sort_values(ascending=False)\n",
    "top_feature_names = top_features.index\n",
    "\n",
    "# Display the top 10 features \n",
    "top_feature_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-bishop",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the features for the USA predictions \n",
    "encoded_values = country_encoder.transform(['USA'])\n",
    "\n",
    "condition = X_test['Country'].isin(encoded_values)\n",
    "X_country_lens = X_test[condition]['Year']\n",
    "\n",
    "shap_values = explainer.shap_values(X_test.loc[X_country_lens.index]) \n",
    "#shap.summary_plot(shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distant-multimedia",
   "metadata": {},
   "source": [
    "### A look at coeffecients for lasso model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-faith",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the coefficients and feature names\n",
    "coefficients = best_lasso_model.coef_\n",
    "feature_names =  X.columns \n",
    "\n",
    "# Create a dictionary with feature names and their coefficients\n",
    "coefficients_dict = dict(zip(feature_names, coefficients))\n",
    "\n",
    "# Sort the features by their absolute coefficients in descending order\n",
    "sorted_features = sorted(coefficients_dict.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "# Print the top 10 sorted features\n",
    "for feature, coefficient in sorted_features[0:11]:\n",
    "    print(f\"{feature}: {coefficient}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-sensitivity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
