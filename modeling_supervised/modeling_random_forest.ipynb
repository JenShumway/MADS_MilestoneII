{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "crazy-northwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "challenging-western",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "allied-tutorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MMRT = pd.read_csv('WorldBankDatasets/Cleaned/AllMerged_Threshold_85_n3_MMRT.csv')\n",
    "df_MMRTNE = pd.read_csv('WorldBankDatasets/Cleaned/AllMerged_Threshold_85_n3_MMRTNE.csv')\n",
    "df_OECD = pd.read_csv('OECD/Cleaned/HEALTH_MERGED_Threshold_80_n3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceramic-royalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select which df to use \n",
    "\n",
    "df = df_MMRTNE\n",
    "indicator_y = 'SH.STA.MMRT.NE'\n",
    "\n",
    "#df = df_MMRT\n",
    "#indicator_y = 'SH.STA.MMRT'\n",
    "\n",
    "#df = df_OECD\n",
    "#indicator_y = 'MATIMATM'\n",
    "\n",
    "# Perform hyperparameter tuning? \n",
    "perform_hp_tuning = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "related-labor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First need to encode the country \n",
    "\n",
    "# Create a LabelEncoder instance for each categorical column\n",
    "country_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the categorical columns\n",
    "data_encoded = df.copy(deep = True)\n",
    "data_encoded['Country'] = country_encoder.fit_transform(data_encoded['Country'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-broadcast",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "irish-rocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out Maternal Mortality as the predictor variable \n",
    "X = data_encoded.drop(columns= indicator_y)\n",
    "y = data_encoded[indicator_y]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-perfume",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-outdoors",
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_hp_tuning:   \n",
    "\n",
    "    # Create a Random Forest Regressor\n",
    "    rf_regressor = RandomForestRegressor(random_state=42)\n",
    "\n",
    "    # Define a grid of hyperparameters to search\n",
    "    parameter_grid = {\n",
    "        'n_estimators': [10, 20, 40],           \n",
    "        'max_depth': [None, 10, 20, 30, 40, 50],         \n",
    "        'min_samples_split': [2, 5, 10, 20],         \n",
    "        'min_samples_leaf': [1, 2, 4, 6, 10, 20],                   \n",
    "        'bootstrap': [True, False]               \n",
    "    }\n",
    "\n",
    "    # Create a GridSearchCV object with cross-validation\n",
    "    grid_search = GridSearchCV(estimator = rf_regressor, param_grid = parameter_grid, cv=5)  \n",
    "\n",
    "    # Fit the grid search to the data\n",
    "    grid_search.fit(X, y)  \n",
    "\n",
    "    # Get the best hyperparameters\n",
    "    best_hyperparameters = grid_search.best_params_\n",
    "\n",
    "    # Get the best Random Forest Regressor model\n",
    "    best_rf_regressor = grid_search.best_estimator_\n",
    "\n",
    "    best_n_estimators = best_hyperparameters['n_estimators']\n",
    "    best_max_depth = best_hyperparameters['max_depth']\n",
    "    best_min_samples_split = best_hyperparameters['min_samples_split']\n",
    "    best_min_samples_leaf = best_hyperparameters['min_samples_leaf']\n",
    "    best_bootstrap = best_hyperparameters['bootstrap']\n",
    "    \n",
    "    print(f\"Best n_estimators: {best_n_estimators}\")\n",
    "    print(f\"Best max_depth: {best_max_depth}\")\n",
    "    print(f\"Best min_samples_split: {best_min_samples_split}\")\n",
    "    print(f\"Best min_samples_leaf: {best_min_samples_leaf}\")\n",
    "    print(f\"Best bootstrap: {best_bootstrap}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-consciousness",
   "metadata": {},
   "source": [
    "### 5 Fold Cross Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valued-advancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store the mean squared errors (MSE) for each fold\n",
    "mse_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "# initialize the best r2 score \n",
    "best_r2_score = -100000\n",
    "best_model = None\n",
    "\n",
    "\n",
    "# Create a Random Forest Regressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=best_n_estimators, max_depth = best_max_depth,\n",
    "                                     min_samples_split = best_min_samples_split, min_samples_leaf = best_min_samples_leaf,\n",
    "                                     bootstrap = best_bootstrap, random_state=42)  \n",
    "\n",
    "# Create a KFold cross-validator with 5 folds\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = rf_regressor.predict(X_test)\n",
    "\n",
    "    # Calculate the mean squared error (MSE) for this fold\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_scores.append(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    r2_scores.append(r2)\n",
    "    \n",
    "    # Keep the best model based on r2 score\n",
    "    if r2 > best_r2_score:\n",
    "        # Save the best r2 score and best model\n",
    "        best_r2_score = r2\n",
    "        best_model = rf_regressor\n",
    "        # Save the respective train test split\n",
    "        X_train_best = X_train\n",
    "        X_test_best = X_test\n",
    "        y_train_best = y_train\n",
    "        y_test_best = y_test\n",
    "\n",
    "# Calculate the mean and standard deviation of the MSE scores and r2 scores\n",
    "mean_mse = np.mean(mse_scores)\n",
    "std_mse = np.std(mse_scores)\n",
    "mean_r2 = np.mean(r2_scores)\n",
    "std_r2 = np.std(r2_scores)\n",
    "\n",
    "print(f\"Average Mean Squared Error (MSE): {mean_mse}\")\n",
    "print(f\"Standard Deviation of Mean Squared Error (MSE): {std_mse}\")\n",
    "print(f\"Mean R-squared (R2): {mean_r2}\")\n",
    "print(f\"Standard Deviation of R-squared (R2): {std_r2}\")\n",
    "print(f\"Best R-squared (R2): {best_r2_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-jacob",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-establishing the train test split from the best model \n",
    "X_train = X_train_best\n",
    "X_test = X_test_best \n",
    "y_train = y_train_best \n",
    "y_test = y_test_best\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-worship",
   "metadata": {},
   "source": [
    "### A Look at Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = best_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-jonathan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort features by importance in descending order\n",
    "sorted_indices = np.argsort(feature_importance)[::-1][:10] # pull only the top 10 features\n",
    "sorted_feature_names = X.columns[sorted_indices]\n",
    "sorted_importances = feature_importance[sorted_indices]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(len(sorted_importances)), sorted_importances)\n",
    "plt.yticks(range(len(sorted_importances)), sorted_feature_names)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importance Plot')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
